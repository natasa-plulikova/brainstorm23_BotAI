{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9972d73e-ea16-47dc-9daf-58a611754ce1",
   "metadata": {},
   "source": [
    "# Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4725527-6792-4d08-89cf-9f74b2161860",
   "metadata": {},
   "source": [
    "![AI_trend](img/AI_trend.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ad5ef-ff40-4718-a014-ee1484ff30f9",
   "metadata": {},
   "source": [
    "Large Language Model (LLM) is a foundational model to serve tasks that concern language."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02e508b2-bdae-40c1-b616-47439159a69f",
   "metadata": {},
   "source": [
    "![masked_model](img/masked-model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bc8f53b",
   "metadata": {},
   "source": [
    "Training of foundational models is done in semi-supervised way. The same sentence serves as input and output, however on the input side some tokens are masked. When run on large amounts of data, the models are able to capture the semantics and structure of a language and can perform well over numerous tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92af7a-0d6d-42c0-b003-1d54ad714b26",
   "metadata": {},
   "source": [
    "### Set up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebe657c-654f-4678-964c-e5a22001ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72e06ac-27e1-453e-8af1-bfb95ae38097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from genai.credentials import Credentials\n",
    "from genai.model import Model\n",
    "from genai.schemas import GenerateParams\n",
    "\n",
    "\n",
    "apikey = os.environ[\"APIKEY\"]\n",
    "url = os.environ[\"URL\"]\n",
    "creds = Credentials(apikey, url)\n",
    "\n",
    "params = GenerateParams(\n",
    "            decoding_method=\"greedy\",\n",
    "            repetition_penalty=1.5,\n",
    "            moderations={\"hap\": {\"input\": True, \"threshold\": 0.75, \"output\": True}},\n",
    "        )\n",
    "\n",
    "llm = Model(\"google/flan-ul2\", params=params, credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2ae1f8-ddd9-470c-9f9e-1fa024be9fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, thanks.\n"
     ]
    }
   ],
   "source": [
    "response = llm.generate([\"Hello, how are you?\"])\n",
    "print(response[0].generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ef136-2e23-48dd-be22-b721ce0d59cf",
   "metadata": {},
   "source": [
    "### Introduce Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2325bd-dc24-493a-b0b3-ca642191ffb0",
   "metadata": {},
   "source": [
    "The idea of composing components together in a chain is simple but powerful. It drastically simplifies and makes more modular the implementation of complex applications, which in turn makes it much easier to debug, maintain, and improve your applications.\n",
    "Read more on chains with langchain: https://python.langchain.com/docs/modules/chains/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e88388-ee69-40b9-a83c-03414205e86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good, thanks.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genai.extensions.langchain import LangChainInterface\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm_langchain = LangChainInterface(model=\"google/flan-ul2\", params=params, credentials=creds)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\",\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm_langchain, prompt=prompt)\n",
    "\n",
    "llm_chain.run(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c831f26-fa4c-437a-a997-77f95d53e63f",
   "metadata": {},
   "source": [
    "### Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcd052-ad85-4da5-ad14-09f26901d483",
   "metadata": {},
   "source": [
    "Quality of the LLM response will depend on what prompt you use to receive answer. Prompts can be as simple as instruction or question that you pass to your model. More advanced prompts can contain also additional context or examples for the model to learn from.\n",
    "Good reading on prompt enginnering can be found here: https://www.promptingguide.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcfef2-a7bb-4409-9ff1-7a4d0fc8701f",
   "metadata": {},
   "source": [
    "Example of a single prompt:\n",
    "\n",
    "Prompt:\n",
    "```\n",
    "The sky is\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76b854a-992c-48ef-a4fe-f47c661576ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blue.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"The sky is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4be2d-f321-4740-a681-064d0204c0d2",
   "metadata": {},
   "source": [
    "We can improve the model by giving it also an instruction. Such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ecb428-669f-44e0-a123-80c51a9b8897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blue because the sun is out and it is a sunny day.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"Complete the sentence below.\\n The sky is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7f34d-f57a-431b-abdb-7948a77b3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out some other instructions to get:\n",
    "# - response that is poetic/creative\n",
    "# - short response\n",
    "# - logic and scientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ac5cdf-c3fd-417a-ab03-c3dd835ce403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the sky is blue because of refraction of light'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd0c20-e6c3-4faf-b8a6-1cdf8d7617ae",
   "metadata": {},
   "source": [
    "With langchain, you can also reformat your prompt so that you do not have to always include the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bd0a71-1e8c-49da-a631-3f1cc193b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mComplete the sentence below:\n",
      "    The sky is\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blue because the sun is out and it is a sunny day.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=\"\"\"Complete the sentence below:\n",
    "    {input}\"\"\",\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm_langchain, prompt=prompt, verbose=True)\n",
    "\n",
    "llm_chain.run(\"The sky is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the prompt format so that it can accomodate following examples:\n",
    "\n",
    "# question: What is the capital of Slovakia?\n",
    "# answer: Bratislava\n",
    "\n",
    "# question: What is the capital of Brazil?\n",
    "# answer: Brasilia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d62d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bratislava\n",
      "Brasilia\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"country\"], # define your parameter\n",
    "    template = \"\"\"\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm_langchain, prompt=prompt)\n",
    "print(llm_chain.run(\"Slovakia\"))\n",
    "print(llm_chain.run(\"Brazil\"))\n",
    "\n",
    "# Question: How can you make the LLM to answer with capital letters (e.g. not bratislava but Bratislava)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9ad5f1e",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31b466-529e-484a-88c3-544e966e5cfa",
   "metadata": {},
   "source": [
    "![RAG](img/RAG_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531d15f",
   "metadata": {},
   "source": [
    "### Step 1: Prepare your knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02402dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we read our pdf file\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf = \"data/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT).pdf\"\n",
    "pdf_reader = PdfReader(pdf)\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acb09d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document has approx. 79584 words\n"
     ]
    }
   ],
   "source": [
    "print(f\"The document has approx. {len(text.split())} words\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "384b10fd",
   "metadata": {},
   "source": [
    "### Split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "971ed6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 524, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0\n",
      "Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. \n",
      "The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
      "chunk 1\n",
      "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n"
     ]
    }
   ],
   "source": [
    "# We do not want to treat the document as one big chunk of text, rather, it would be easier to split it into smaller pieces that are retrieved based on their relevancy to our question.\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "example_doc = \"\"\"\n",
    "Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. \n",
    "The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
    "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
    "Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems.\n",
    "ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.\n",
    "Within a nervous system, a neuron, neurone, or nerve cell is an electrically excitable cell that fires electric signals called action potentials across a neural network. \n",
    "Neurons communicate with other cells via synapses - specialized connections that commonly use minute amounts of chemical neurotransmitters to pass the electric signal from the presynaptic neuron to the target cell through the synaptic gap. \n",
    "\"\"\"\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "example_chunks = text_splitter.split_text(example_doc)\n",
    "\n",
    "# check how the text splitter works\n",
    "print(\"chunk 0\")\n",
    "print(example_chunks[0])\n",
    "print(\"chunk 1\")\n",
    "print(example_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "891d301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise:\n",
    "# write code that will split the text of our pdf document into smaller chunks\n",
    "# try using RecursiveCharacterTextSplitter instead of CharacterTextSplitter\n",
    "\n",
    "# Type your code here:\n",
    "\n",
    "# text_splitter = ...\n",
    "\n",
    "chunks = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7015a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 3360\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3e47099",
   "metadata": {},
   "source": [
    "### Add embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29762ecc",
   "metadata": {},
   "source": [
    "Embeddings are vector representations of tokens (or words) in a space that keep semantic similarity of words. Vectors that are close together are considered similar. In order to do efective search over our knowledgebase, we need to store our texts as embeddings so that we can easily retrieve most semantically accurate chunks to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9fa68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natasa/Projects/brainstorm-2023/workshop/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of our embeddings\n",
      "4 768\n"
     ]
    }
   ],
   "source": [
    "# langchain class for embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                model_kwargs={'device': 'cpu'},\n",
    "                encode_kwargs={'normalize_embeddings': False}\n",
    "                )\n",
    "\n",
    "# try it out\n",
    "\n",
    "example_embeddings = embedding_model.embed_documents(example_chunks)\n",
    "print(\"Dimension of our embeddings\")\n",
    "print(len(example_embeddings), len(example_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aefdb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning. \n",
      "The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.\n",
      "[[0.02370083]]\n",
      "Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "[[0.12612669]]\n",
      "Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems.\n",
      "ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.\n",
      "[[0.04992809]]\n",
      "Within a nervous system, a neuron, neurone, or nerve cell is an electrically excitable cell that fires electric signals called action potentials across a neural network. \n",
      "Neurons communicate with other cells via synapses - specialized connections that commonly use minute amounts of chemical neurotransmitters to pass the electric signal from the presynaptic neuron to the target cell through the synaptic gap.\n",
      "[[0.0562752]]\n"
     ]
    }
   ],
   "source": [
    "# check with cosine similarity which documents are closer to my example query\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "example_query = \"I like dogs and cats\"\n",
    "query_emb = embedding_model.embed_query(example_query)\n",
    "\n",
    "for i, ex in enumerate(example_embeddings):\n",
    "    print(example_chunks[i])\n",
    "    print(cosine_similarity([query_emb], [ex]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36d259cf",
   "metadata": {},
   "source": [
    "### Define vector store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a79689a",
   "metadata": {},
   "source": [
    "Vector store is a type of database that can store unstructured data in an organized way. Typically, text is stored alongside with its embeddings (or vectors) and search is done as a similarity search over these vectors.\n",
    "&nbsp;\n",
    "\n",
    "![vectorstore](img/vectorstore.png)\n",
    "&nbsp;\n",
    "source: https://python.langchain.com/docs/modules/data_connection/vectorstores/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dded95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "# we will use FAISS for this exercise, but you can easily use Chromadb, Milvus, Elasticsearch, etc.\n",
    "# https://python.langchain.com/docs/integrations/vectorstores\n",
    "\n",
    "knowledge_base = FAISS.from_texts(chunks, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "625293cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out your knowledge base\n",
    "\n",
    "query = \"What is deep neural network?\"\n",
    "docs = knowledge_base.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2299439-f142-4cfc-8cbc-b9bad0d26fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='together.Forexample,wemighthavethreefunctions f( 1 ), f( 2 ),and f( 3 )connected\\ninachain,toform f(x) = f( 3 )( f( 2 )( f( 1 )(x))).Thesechainstructuresarethemost\\ncommonlyusedstructuresofneuralnetworks.Inthiscase, f( 1 )iscalledtheﬁrst\\nlayerofthenetwork, f( 2 )iscalledthesecondlayer,andsoon.Theoverall\\n168CHAPTER6.DEEPFEEDFORWARDNETWORKS\\nlengthofthechaingivesthedepthofthemodel.Itisfromthisterminologythat\\nthename“deeplearning”arises.Theﬁnallayerofafeedforwardnetworkiscalled\\ntheoutputlayer.Duringneuralnetworktraining,wedrive f(x)tomatch f∗(x).\\nThetrainingdataprovidesuswithnoisy,approximateexamplesof f∗(x) evaluated\\natdiﬀerenttrainingpoints.Eachexamplexisaccompanied byalabel y f≈∗(x).\\nThetrainingexamplesspecifydirectlywhattheoutputlayermustdoateachpoint\\nx;itmustproduceavaluethatiscloseto y.Thebehavioroftheotherlayersis\\nnotdirectlyspeciﬁedbythetrainingdata.\\xa0Thelearningalgorithmmustdecide\\nhowtousethoselayerstoproducethedesiredoutput,butthetrainingdatadoes')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Ideally, this would go to some cloud database, for this demo, we are just using a local storage so let's pickle the knowledge base for later use\n",
    "with open(\"knowledge_base.pkl\", \"wb\") as file:\n",
    "    pickle.dump(knowledge_base, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f5e9b",
   "metadata": {},
   "source": [
    "### Step 2: Define your QA chain over documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b38905",
   "metadata": {},
   "source": [
    "In case the code did not run, please use this link to download the `knowledge_base.pkl` directly: https://ibm.box.com/s/133tnvy1fsmxtju3z5vo3insblx7zzhz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a96b8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell in case something went wrong in the previous chapter\n",
    "import pickle\n",
    "with open(\"knowledge_base.pkl\", \"rb\") as file:\n",
    "    knowledge_base = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd591799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To summarize, deep learning, the subject of this book, is an approach to AI. Specifically, it is a type of machine learning, a technique that allows computer systems to improve with experience and data. According to the authors of this book, machine learning is the only viable approach to building AI systems that can operate in complicated, real-world environments. Deep learning is a particular r e i nf o r c e m e n t l e ar ni ng.\n"
     ]
    }
   ],
   "source": [
    "# the easiest way is to use pre-defined qa chain from langchain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "params = GenerateParams(\n",
    "            decoding_method=\"greedy\",\n",
    "            repetition_penalty=1.5,\n",
    "            moderations={\"hap\": {\"input\": True, \"threshold\": 0.75, \"output\": True}},\n",
    "            min_new_tokens=50,\n",
    "            max_new_tokens=200\n",
    "        )\n",
    "\n",
    "\n",
    "query = \"What is deep learning?\"\n",
    "\n",
    "docs = knowledge_base.similarity_search(query)\n",
    "llm_langchain = LangChainInterface(model=\"google/flan-ul2\", params=params, credentials=creds)\n",
    "\n",
    "chain = load_qa_chain(llm_langchain, chain_type='stuff')\n",
    "response = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7842fab",
   "metadata": {},
   "source": [
    "## Another way how to define your QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5e50f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define a prompt to handle user's question\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Use a formal language to answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Helpful Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"sample\",\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.5,\n",
    "    moderations={\"hap\": {\"input\": True, \"threshold\": 0.75, \"output\": True}},\n",
    "    min_new_tokens=50,\n",
    "    max_new_tokens=200\n",
    ")\n",
    "llm_model = LangChainInterface(model=\"google/flan-ul2\", params=params, credentials=creds)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm_model, prompt=qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8504335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: define your chain that will handle creation of context\n",
    "\n",
    "from langchain.chains import StuffDocumentsChain\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],\n",
    "    template=\"{page_content}\"\n",
    ")\n",
    "\n",
    "document_variable_name = \"context\"\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f377012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To summarize, deep learning, the subject of this book, is an approach to AI. Specifically, it is a type of machine learning, a technique that allows computer systems to improve with experience and data. According to the authors of this book, machine learning is the only viable approach to building AI systems that can operate in complicated, real-world environments. Deep learning is a particular r e i nf o r c e m e n t l e ar ni ng.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is deep learning?\"\n",
    "\n",
    "docs = knowledge_base.search(query, search_type=\"similarity\")\n",
    "stuff_chain.run({\"question\": query, \"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe26367",
   "metadata": {},
   "source": [
    "## Introducing Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "90e23597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To summarize, deep learning, the subject of this book, is an approach to AI. Specifically, it is a type of machine learning, a technique that allows computer systems to improve with experience and data. According to the authors of this book, machine learning is the only viable approach to building AI systems that can operate in complicated, real-world environments. Deep learning is a particular'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of performing the search manually, let the chain handle everything\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "faiss_retriever = knowledge_base.as_retriever()\n",
    "\n",
    "chain = RetrievalQA(combine_documents_chain=stuff_chain, retriever=faiss_retriever)\n",
    "chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69f112",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69967727",
   "metadata": {},
   "source": [
    "![](./img/agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce38489",
   "metadata": {},
   "source": [
    "LLMs suffer from a limitation: they are limited to the knowledge on which they have been trained and the additional knowledge provided as context; as a result, if a useful piece of information is missing the provided knowledge, the model cannot “go around” and try to find it in other sources.\n",
    "\n",
    "This is the reason why we need to introduce the concept of Agents. Agents can be seen as applications powered by LLMs and integrated with a set of tools like search engines, databases, websites, and so on. Within an agent, the LLM is the reasoning engine that, based on the user input, is able to plan and execute a set of actions that are needed to fulfill the request.\n",
    "\n",
    "For more details visit the following website: [Langchain Agents](https://python.langchain.com/docs/modules/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c300b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
